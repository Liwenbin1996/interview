1、最小生成树算法

Kruskal算法
俗称“加边法”。每次迭代选择一个代价最小的边并且这个边所对应的两个顶点不在同一颗当中，将该边加入到最小生成树的边集合中，重复步骤直到所有的顶点都在一棵树当中或者有n-1条边为止。具体方法如下：

<1>将连通图中的每条边按照代价从小到大进行排序。
<2>将所有的顶点单独成树。
<3>每次选择一条代价最小的边，并且满足该边对应的顶点不都在同一棵树当中，将该边加入到最小生成树边集合当中。
<4>重复步骤<3>直到所以的顶点都在一棵树当中或者有n-1条边为止。

Prim算法
俗称“加点法”。使用一个集合，记录当前最小生成树当中的所有顶点，以一个顶点开始，每次迭代，在其余顶点当中选择一个顶点使得这个顶点能够连接到最小生成树当中并且所需代价最小，重复步骤直到最小生成树包含所有的顶点。具体方法如下：

<1>集合V代表所有顶点的集合，集合u代表当前最小生成树当中顶点的集合，集合v代表剩余顶点的集合。选择一个顶点s加入到集合u当中。
<2>在集合v当中选择一个顶点，使得该点能够连接到最小生成树当中并且所需代价最小。
<3>更新u和v，重复步骤<2>直到最小生成树有n-1条边或者有n个顶点为止。



2、STL的数据结构的内部实现

<1>vector
底层数据结构为数组，支持快速随机访问。内部维持三个指针，一个指向已使用空间的头、一个指向已使用空间的尾、一个指向可用空间的尾，便于维护vector的大小和状态。当vector空间不足时则会进行扩容，扩容的方式是以原大小的两倍另外配置一个较大空间，然后将原内容拷贝过来，之后析构原元素，释放原空间。值得注意的是，当对vector进行操作引起vector进行扩容后，原来指向vector的所有迭代器都将失效。

vector的插入操作：
  
  当备用空间大于新增元素个数，并且插入点之后的元素个数n大于新增个数m。首先调用uninitialized_copy将插入点之后的m个元素复制到备用空间，再调用copy_backward复制剩余的n-m个元素，最后使用fill在插入点之后插入m个新元素。
  
  当备用空间大于新增元素个数，并且插入点之后的元素个数n小于新增个数m。首先调用uninitialized_fill_n在末尾添加m-n个新元素，之后使用uninitialized_copy将插入点之后的n个元素复制到备用空间，最后使用fill函数在插入点之后插入n个新元素。
  
  当备用空间小于新增元素个数，vector进行扩容寻找一个更大的空间，使用uninitialized_copy复制插入点前的元素到新空间，之后使用uninitialized_fill_n插入新增元素，最后再使用uninitialized_copy将原插入点之后的元素复制过去。
  
  uninitialized_***会调用相应的构造函数，其余的函数调用的则是赋值函数

<2>list

底层数据结构是双向链表，支持快速增删。list不仅是一个双向链表，而且还是一个环状的双向链表，头和尾之间存在一个空值节点，这样就可以只使用一个指针来表示整个list。

<3>deque

底层数据结构是一个中央控制器和多个缓冲区，逻辑上是连续空间。deque采用一块所谓的map作为主控，map是一小块的连续空间，其中每一个元素都是一个指针，指向一段连续的空间，这个空间称为缓冲区，用于真正存储数据。当需要在deque的前端或后端增加新空间时，便配置一段定量连续空间，在中央控制器中添加一个新指针指向新的空间。deque的底层实现有点像是list和vector的复合体。

为了维持deque空间连续的假象，deque的迭代器要比其他容器的迭代器更加复杂。它维持四个指针，cur指向缓冲中当前的元素，first指向当前缓冲区的头，last指向当前缓冲器的尾，node指向中央控制器中对应的位置，用于快速切换缓冲区。

deque之所以不使用vector作为其底层实现，但是vector从头部插入元素需要O(N)的时间复杂度，并且扩容带来的代价是很大的。

<4>stack
底层一般使用list或deque实现，封闭头部即可。
<5>queue
底层一般使用list或deque实现，封闭底端的出口和前端的入口即可。
<6>priority_queue
底层数据结构为vector，使用堆heap为处理规则来管理数据。
<7>set
底层数据结构为红黑树，有序，不重复。multiset，可重复。
<8>map
底层数据结构为红黑树，有序，不重复。multimap，可重复。
<9>hash_set
底层数据结构是哈希表，无序，不重复。hash_multiset，可重复。
<10>hash_map
底层数据结构是哈希表，无序，不重复。hash_multimap，可重复。



3、linux查看系统的常用命令

查看系统版本：

uname		查看系统内核版本
-a		显示全部信息

cat /etc/issue

查看内存相关：

free		查看内存使用情况
-b/k/m		以Byte/KB/MB为单位显示内存使用情况
-s 10		持续观察内存使用情况，以10s为间隔

查看cpu相关：

uptime		打印系统总共运行了多长时间和系统的平均负载，系统平均负载是指在特定时间间隔内运行队列中的平均进程数。

top		实时监控系统的cpu和内存，默认3s刷新一次
-d<时间>	设置间隔时间
-u<用户名>	指定用户名
-p<进程号>	指定进程
-n<次数>	循环显示的次数

ps		显示当前进程的状态
-A		显示所有的进程
-a		显示不与terminal有关的进程
-u<用户名>	显示指定用户信息
aux		显示系统所有的进程数据
ps aux | sort -k 3nr	按照cpu使用率从大到小排序

cat /proc/cpuinfo

查看硬盘相关：

df		查看磁盘分区的使用情况，默认以KB为单位
-a		查看所有文件系统
-h		以KB以上的单位显示，可读性高
-i		显示inode信息

du		查看目录或文件的大小
-a		显示目录中所有文件的大小
-b		以字节为单位显示
-h		以KB以上的单位显示，可读性高

fdisk		查看磁盘使用情况，也可进行磁盘分区
-l		查看所有安装的磁盘以及分区信息



4、常量指针和指针常量

常量指针，即指向常量的指针，可以指向其他对象，但不能改变指针指向对象的内容。常量指针定义时，const关键字在*的左边。

指针常量，即这个指针指向一个固定的对象，不能再指向其他的对象，但是可以改变指向对象的内容。指针常量定义时，const关键字在*右边。



5、TCP两次握手、三次挥手可以么

不可以。
采用三次握手是为了防止失效的连接请求报文段突然又传送到主机B，因而产生错误。失效的连接请求报文段是指：主机A发出的连接请求没有收到主机B的确认，于是经过一段时间后，主机A又重新向主机B发送连接请求，且建立成功，顺序完成数据传输。考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。
同时，TCP使用三次握手可以确定客户端和服务端的收发状态。客户端先发送一个SYN数据报表明自己可以正确的发送数据报，服务端接受SYN数据报后发送一个ACK数据报，表明自己不仅可以正确接收数据还可以正确发送数据。客户端再次发送一个ACK数据报，表示自己可正确接收数据报。使用两次握手则不能确定客户端的接收状态是否正常。使用四次握手则产生浪费。

TCP使用四次挥手，第1,2次挥手，关闭客户端的发送状态和服务端的接收状态；第3,4次挥手，关闭服务端的发送状态和客户端的接收状态。当客户端数据发送完毕后，服务端的数据不一定发送完毕。因此，如果使用三次挥手，那么服务端未发送完的数据将不能继续发送。



6、域名解析过程

<1>主机像其本地域名服务器进行递归查询
<2>本地域名服务器采用迭代查询。先向根域名服务器查询
<3>根域名服务器告诉本地域名服务器，下一个应该查询的顶级域名服务器的IP地址
<4>本地域名服务器向顶级域名服务器进行查询
<5>顶级域名服务器告诉本地域名服务器，下一个应该查询的权限域名服务器的IP地址
<6>本地域名服务器向权限域名服务器进行查询
<7>权限域名服务器告诉本地域名服务器，所查询主机的IP地址
<8>本地域名服务器将查询结果告诉主机

域名服务器中广泛使用高速缓存用于存放最近查询过的域名信息。



7、Linux的内存管理

Linux采用段页式内存管理。对于物理内存，采用分页机制，将物理内存划分成一个个等大的页框，一般大小是4K。内核维护一个页描述符数组，称为mem_map，每一个物理页框都对应一个页描述符，每个页描述符都有一个指针，指向它所属的地址空间。还有一对指针可以使得它跟其他描述符形成双向链表，这样就可以记录所有的空闲页和一些其他的空间。对于物理内存的每一个区域，都维护一个区域描述符，包含了每个区域内存使用的情况，例如活动页和非活动页的数目。除此之外，还维护一个空闲区数组，数组的第i个元素记录了第一个大小是2^i个连续页的空间的第一个页描述符，对于相同大小的空间，使用页描述符的指针对链接起来。通过这样的内存管理机制有利于之后的内存分配。

Linux分配物理页框采用了伙伴算法，当一个内存请求到达时，首先向上取整到2的幂次方，然后检查系统中是否有这个大小的内存块。如果有，直接分配即可。如果没有，就向更大的内存块请求，并将该内存块不断二分直到大小刚好满足请求。如果页面被释放，那么原来是一个整体的两个内存块会重新整合再一起。伙伴算法导致了大量的内部碎片，比如想要65个页大小的块，只能分配一个128的块。为了解决这个问题，Linux采用了slab分类器的技术。对于一个内存请求，它仍然通过伙伴算法得到一个内存块，但是之后还要从其中切出多余的空间，大于的空间继续放回空闲链表。小的内存碎片称之为slab，这些slab可以用于对象缓存，因为在内核中需要频繁的创建和撤销一定类型的对象，比如进程描述符，这时候可以使用slab，它在使用完之后并不直接释放而是被缓存起来，留作下次使用。这样就避免了频繁创建和销毁对象所带来的额外负载。除了用于对象缓存，slab还可以用来处理小块内存的请求。

Linux采用虚拟内存管理技术，每个进程都有一个相互独立的地址空间，它采用分段的内存管理，逻辑上分为三段：代码段、数据段和堆栈段。为了能够将虚拟内存真正对应到物理内存上，将每一个段都进行分页。通过维护一个页表（Linux采用四级页表），保存虚拟页面和物理页面的映射。

Linux是一个请求换页系统，一个进程并不需要完全在内存中。页面是在它们被引用的时候动态载入的，如果内存空间不够，还会使用相应的页面置换算法将一些暂时不用的页面换出到对换区或者磁盘。



8、超大文件中数据查找

问题1：找出大数据中词频最高的数据

首先使用hash映射，比如hash(i)%1000，将大数据分散到1000个小文件中，之后使用哈希表对每个数据进行词频统计。找到每个小文件中出现词频最大的数据，之后在这1000个数据中找出词频最大的那个数据。具体将数据分割成多少份根据内存来决定，使得分割后的小文件可以加载到内存中即可。

问题2：找出大数据中出现词频最高的前K个数

使用hash映射对大数据进行分组存放，对于每个小文件使用哈希表进行词频统计，之后使用小根堆查找每个小文件中出现词频最高的前K个数，最后在所有的TopK中找出最终的TopK。

问题3：找出两个超大文件中相同的记录

使用hash映射对A文件进行分组存放，使用同一个哈希函数对B文件进行分组存放。之后，读取小文件Ai中每一个记录，建立哈希表，然后再遍历文件Bi中的每一条记录，对于每次遍历，都在哈希表中查找是否包含此记录，如果能找到，说明该记录就是两个超大文件中共有的记录，保存在另一个文件中即可。



9、在浏览器输入一个URL至页面呈现发生了什么

<1>域名解析
<2>与服务器三次握手建立连接
<3>客户端按照指定的格式向服务端发送http请求
<4>服务端接收请求后，解析http请求，返回一个http响应给客户端
<5>服务端在数据传输完毕后即关闭连接
<6>浏览器渲染页面，并响应用户操作



10、 TCP的状态转换

客户端：CLOSE -> SYN_SENT -> ESTABLISHED ...->FIN_WAIT_1 -> FIN_WAINT_2 ->
TIME_WAIT

服务端：CLOSE -> LISTEN -> SYN_RECV -> ESTABLISHED ...-> CLOSE_WAIT ->
LAST_ACK



11、进程间通信、线程间通信机制

<1> 消息传递：管道、有名管道、消息队列
<2> 同步：互斥锁、信号量、条件变量
<3> 共享内存

进程间：

<1>管道和有名管道

管道是由内核管理的一个缓冲区，它的一端连接一个进程的输出，另一端连接一个进程的输入。管道是半双工的，数据只能单向流动，如果要实现双向通信就必须建立两个管道，由于管道不具有名字，所以它只能在有亲缘关系的进程中通信。当两个进程都终止后，管道的生命周期也就结束了。

有名管道提供一个路径名与之相关联，以FIFO的文件形式存在于文件系统中。因此，无亲缘关系的进程也可以通过该路径名访问管道，也就实现了无亲缘关系的进程间的通信。

<2>消息队列

消息队列可以认为是一个消息链表，有进程向其中放置消息，有进程从中取走消息。在某个进程往消息队列写入消息之前，并不需要有进程等待消息的到达，这和管道是不一样的，对于管道而言，如果没有读出者，先有写入者是没有意义的。消息队列不会随进程的终止而消失。

<3>互斥锁

一般用于线程同步，如果互斥锁存放在多个进程共享的内存区中，那么也可以用于进程同步。
互斥锁用于保护临界区，保证任何时刻只有一个线程在执行其中的代码。每个时刻只能有一个线程对互斥锁上锁，当其他线程尝试对互斥锁上锁，就会进入阻塞状态，直到该互斥锁解锁为止。

一般形式如下：

lock_the_mutex(...)
临界区
unlock_the_mutex(...)

<4>条件变量

互斥锁解决互斥问题，条件变量解决等待问题。每一个条件变量总是与一个互斥锁相关联。如果某个线程因为等待某个条件成立而不断进行轮询操作，这时可以使用条件变量。当条件不满足时就对该条件变量调用wait操作，先给互斥锁解锁，然后将该线程就投入睡眠，直到另外某个线程调用signal操作，它才重新获得锁。

等待条件代码：

pthread_mutex_lock(&mutex);
while(条件为假)	
    pthread_cond_wait(cond, mutex);
修改条件
pthread_mutex_unlock(&mutex);

使用while的原因：唤醒条件的信号，可以唤醒多个线程，但是只能允许一个线程访问，因此，为了避免虚假的唤醒，需要不断轮询直到达到条件。

修改条件代码：

pthread_mutex_lock(&mutex);
设置条件为真
pthread_cond_signal(cond);
pthread_mutex_unlock(&mutex);

<5>信号量

信号量解决进程间同步问题。互斥锁就是一个特殊的信号量。如果一个线程所需要的资源的个数为0，那么必须阻塞直到其他线程释放该类资源。

生产者消费者问题：

full = 0
empty = 10
mutex = 1

producer:

P(empty)
P(mutex)
produce()
V(mutex)
V(full)

consumer:

P(full)
P(mutex)
consume()
V(mutex)
V(empty)

注意两个P操作的顺序，如果顺序颠倒就可能会陷入死锁。

<6>套接字
<7>共享内存

线程间：
<1>锁机制
<2>信号量机制
<3>条件变量



12、智能指针的作用

智能指针的作用在于能自动释放指针，减少人为使用new和delete所存在的内存问题。也就是手动申请，自动释放。具体做法是，智能指针内部有一个计数器，记录着所管理的内存被多少个指针所引用，如果有新的引用，计数器加1，反之减1，如果计数器减为0，那么就会释放该内存。



13、Linux中du和df的区别

du
是通过搜索文件，将各个文件所占的内存大小累加起来，只能包含现在存在的没有被删除的文件。

df
是通过文件系统获取硬盘的使用情况，当一个文件删除的时候，并不会直接消失，而是等到所有的进程都不使用的时候，再由系统根据相应的规则释放。df相比du的不同之处就在于它计算大小的时候可以包含已删除的文件。



14、纯虚函数作用和实现方式

在很多时候，基类本身生成对象是不合理的，比如动物可以派生出猫狗等子类，但是动物自己生成对象是不合理的。为了解决这个问题，可以在类中将函数定义为纯虚函数，这样在派生类中必须重写这个函数以实现多态性，同时，拥有纯虚函数的类成为抽象类，不能生成对象。这样就很好的解决了上述问题。

纯虚函数的实现方式为： virtual type function() = 0;



15、树高度的求法

如果只有一个节点，那么树的高度为1，如果根节点只有左孩子，那么树的高度等于根节点左子树的高度加一；同理，如果只有右孩子，树的高度等于根节点的右子树的高度加1；如果左右孩子都有，那么树的高度等于左子树和右子树高度较大的加1。



16、求最长公共子序列

动态规划。如果两个字符串的长度分别为n和m，生成n*m的dp数组。
dp[i][j]的含义是str1[0...i]和str2[0...j]的最长公共子序列的长度。dp数组的求解如下：

<1>第一行，如果str1[0] == str2[j]，则dp[0][j] = 1，第一列同理。
<2>对于其余为止，dp[i][j]的值可能来自以下三种情况：
  1)dp[i][j-1]
  2)dp[i-1][j]
  3)如果str1[i] == str2[j]，还可能是dp[i-1][j-1]+1
  选择三种当中的最大的即可。

根据dp[n-1][j-1]可知str1和str2最长公共子序列的长度，并由此根据dp数组即可得到最长公共子序列。方法如下：
从dp数组的右下角开始，如果其值等于左边位置的值，左移；如果等于右边位置的值，上移；否则，该位置处所对应的字符就是最长公共子序列当中的一个。重复上述步骤即可找到最长公共子序列。



17、Linux文件权限的修改

example:
chmod 777 test.c
第一个7，设置文件所有者权限
第二个7，设置群组访问权限
第三个7，设置其他人访问权限



18、先递增后递减的数组中找最值

二分查找，判断是否单调递增或单调递减，如果是，答案显而易见。否则利用二分查找。



19、查找链表中倒数第K个值

利用快慢指针slow和fast，开始都指向头节点。先另fast走k-1步，如果fast走到NULL，说明链表长度小于K，不存在倒数第K个值；否则，slow和fast开始同步走，当fast->next=NULL时slow指向的元素就是答案。



20、排序的数组中找绝对值最小数

二分查找。首先根据首尾判断是否都是正数或者负数，如果是的话，答案显而易见。否则利用二分查找。



21、TCP三次握手

首先客户端向服务端发送一个数据报，SYN置1，seq=u（随机产生），此时客户端进入SYN-SENT状态；
服务端接受到数据报，根据SYN位可知这是一个请求连接的数据报，之后发送一个确认数据报，SYN置1，ACK置1，确认序号ack=u+1，序号seq=v（随机产生）。此时客户端进入SYN-RCVD状态；
客户端接受到确认数据报后，向服务端发送一个确认数据报，ACK置1，确认序号ack=v+1，seq=u+1；此时双方便都进入ESTABLISHED状态。



22、红黑树的插入，红黑树的用途

红黑树（Red Black Tree） 是一种自平衡二叉查找树。

首先需要知道红黑树满足5个性质：
<1>红黑树只有红节点和黑节点两种节点
<2>根节点必须为黑节点
<3>所有的叶节点必须为黑节点，这里的叶节点指的是NULL节点
<4>所有红节点的子节点必须为黑节点
<5>从任何一个节点到其每个叶子的所有简单路径都包含相同数目的黑色结点

插入节点的时候首先按照二叉搜索树插入的方法插入，并且将该节点设置为红色。在此基础上，节点的插入又分为3种情况：

<1>如果是插入到空树当中，那么只需要将插入的节点的颜色改成黑色即可。
<2>如果插入节点的父节点是黑色的，不需要任何调整。
<3>如果插入节点的父节点是红色的，那么此时红黑树就不满足性质：所有的红节点的子节点必须为黑节点。这个时候，红黑树就需要调整。具体的调整分为2中情况，下面以父节点是祖父节点的左孩子进行讲解，父节点是祖父节点右孩子的情况与之原理一致：

1)如果插入节点的父节点为红，叔父节点为黑。
如果插入节点是父节点的左孩子，那么先对父节点进行一次右旋转的过程，即父节点旋转到祖父节点的位置，同时改变父节点的颜色为黑，然后将原祖父节点的颜色改为红即可。
如果插入节点是父节点的右孩子，那么需要进行两次旋转的过程，首先对插入节点进行一次单纯左旋转，使得红黑树变成“左左”的状态，之后再向上面一样进行一次右旋转即可。

2)如果插入节点的父节点和叔父节点均为红，此时必定存在祖父节点且一定为黑，那么将父节点和叔父节点都设置为黑，将祖父节点设置为红，此时，将祖父节点当做新节点，再进行各种情况的判断，即进入递归过程。

红黑树的用途：
红黑树多用在内部排序，即全放在内存中的，微软STL的map和set的内部实现就是红黑树。



23、进程线程区别

进程：程序的一次执行
线程：CPU的基本调度单位
进程相当于一个容器，当要执行一个作业，进程包含执行该作业所需要的全部系统资源，但是作业的完成是靠线程来进行的。

<1>进程是资源分配的最小单位，线程是程序执行的最小单位。
<2>一个进程至少包含一个线程，也可以包含多个，线程共享整个进程的资源。
<3>进程结束后所有的线程将被销毁，而线程的结束不会影响同个进程中的其他线程。
<4>线程中执行时一般都要进行同步和互斥，因为他们共享同一进程的所有资源
<5>线程是轻量级的进程，它的创建和销毁所需要的时间比进程小很多



24、进程调度算法

<1>先来先服务算法

<2>最短作业优先算法

<3>最高响应比优先法	

响应比 =（等待时间+要求服务时间）/ 要求服务时间

<4>时间片轮转算法

<5>多级反馈队列算法

有多个队列，优先级依次递减，高优先级队列中的进程先运行。对于优先级最低的队列来说，遵循时间片轮转算法。其余队列遵循先来先服务算法，每一个进程分配一个时间片，如果时间片用完进程尚未结束，就进入下一优先级队列的末尾。



25、TCP、UDP的区别

TCP是面向连接的、可靠的、面向字节流的传输层协议

UDP是无连接的、不可靠的，面向报文的传输层协议

TCP要求系统资源较多，UDP较少

TCP连接只能是点对点的，UDP支持一对一、一对多、多对一和多对多的交互通信

TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道



26、TCP/IP模型各层的协议及作用

应用层：

为应用程序提供服务，完成应用程序与应用程序之间的通信，包括文件传输、电子邮件
HTTP、Telnet(Internet远程登陆服务的标准协议)、FTP、TFTP、DNS、SMTP(Simple Mail Transfer Protocol)

传输层：

提供端到端之间的通信
TCP、UDP

网络层：

提供IP选址和路由选择功能
IP、ICMP(在IP主机、路由器之间传递控制消息)、IGMP(提供internet网际多点
传送的功能)、RIP(动态路由选择协议)

数据链路层：

将网络层的数据报封装成帧，把帧从原MAC地址传到目的MAC地址。提供差错检测，只检测有没有比特错误，若有则丢弃。
ARP、RARP、PPP、CSMA/CD

物理层：

以二进制数据形式在物理媒体上传输数据
RJ-45、IEEE802.3



27、哈希表的原理、解决冲突的方式

散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。

<1>开放定址法：在冲突的位置，顺序查看下一单元找到空单位（线性探测再散列，还有二次、伪随机）
<2>再哈希法：同时构造多个不同的哈希函数
<3>链地址法：将所有哈希地址为i的元素构成一个单链表
<4>建立公共溢出区：将哈希表分为基本表和溢出表，一旦发生冲突就填入溢出表



28、C、C++的区别以及C++的优势

区别：
C++在C的基础上添加类和模板
C是面向过程的，C++是面向对象的
C侧重的是对输入的数据进行一系列的运算得到最终结果；C++侧重的是通过构造一个对象模型，使这个模型契合实际的问题，通过操作对象和获取该对象的信息来得到结果。

优点：
C++的优点主要体现在面向对象的三大性质上，封装、继承和多态。封装使得代码能够隐藏实现细节，实现代码的模块化；继承可以在原来的代码模块上进行扩展，封装和继承实现了代码的重用；多态可以使用一个公共类，访问和调用不同对象，实现了接口重用。



29、C++11新特性

例举部分如下：

引入nullptr，取代NULL，专用于空指针
引入constexpr，近似const，可修饰变量，也可以修饰函数，修饰的函数生效于编译时而不是运行时
引入auto类型，编译器通过初始值来推算类型变量，是容器迭代更加方便
引入decltype，可以获取变量的类型
引入元组，实现函数返回多个值
引入default关键字可以在类中生成默认构造函数和析构函数



30、什么是线程池

线程池就是使用有限数量的线程处理单个任务小但是数量巨大的应用，比如WEB服务器完成网页请求这样的任务。假设有5万条网页请求，如果不使用线程池就需要创建5万个线程，线程使用完后还要进行销毁，这会带来很大的时间和空间大的消耗。线程池的作用就是限制系统中执行线程的数量。使用线程池可以有效的减少创建和销毁线程的次数，每个工作线程都可以被重复利用。



31、C++内存管理，各自存放什么数据

栈区：由编译器自动分配释放，存放函数的参数值、局部变量等。可静态也可动态分配

堆区：一般由程序员分配释放，如果程序员不释放，程序结束时可能由OS回收。存放由new分配的数据块等

全局区(静态区)：程序结束后由系统释放，存放全局变量和静态变量

文字常量区：程序结束后由系统释放，存放常量值，不允许修改

程序代码区：存放函数体的二进制代码



32、IO复用技术

IO复用是Linux中的IO模型之一，IO复用就是预先告诉内核需要监视的进程和事件类型，当事件发生时就处理相应进程，从而不会阻塞在单个IO上。Linux中使用select、epoll实现IO复用。

select:

select机制首先使用3个位数组用于监视3种不同的事件，分别是读事件，写事件，异常事件。最左边的位表示文件描述符0，以此类推，如果某个位设置为1，那么对应的文件描述符就是监视对象。通过调用select函数来对这3个位数组进行轮询监视，当select函数调用完成后，位数组中仍然为1的位置表示发生了事件，其余位置全部清零。因为每次都要对没有发生事件的位置进行清零，所以在每次调用select之前都要重新设置3个位数组。在调用select函数的时候还要进行超时设置，如果规定的时间内没有时间发生则退出函数，超时时间在每次调用select函数时都需要重新设置，否则默认使用的是剩余时间。

epoll:

epoll机制不需要像select一样使用3个位数组保存监视对象的文件描述符，它是直接由操作系统负责监视对象文件描述符，我们只需要告诉操作系统保留多大空间即可。对于需要监视的文件描述符我们只需要在系统中注册一次就可以。当epoll函数调用完成后，它会将所有发生事件的文件描述符集中保存到一个数组当中，因此epoll无需对所有的文件描述符进行循环。

select和epoll的区别

<1>调用select后需要对所有的文件描述符进行循环，epoll只需要对发生变化的文件描述符进行循环。

<2>每次调用select都需要传递监视对象信息，epoll对于需要监视的文件描述符只需要注册一次。



33、7层网络协议栈和5层网络协议栈的区别

TCP/IP协议中的应用层处理OSI模型中的第五层、第六层和第七层的功能。
 
TCP/IP协议中的传输层并不能总是保证在传输层可靠地传输数据包，而OSI模型可以做到。TCP/IP协议还提供一项名为UDP（用户数据报协议）的选择。UDP不能保证可靠的数据包传输。



34、ARP、RARP协议工作流程

ARP：IP -> MAC
当主机A要与主机B进行通信的时候，A会先在自己的ARP缓存中寻找是否有B的MAC地址，如果没有，主机A会放送一个ARP请求广播包，主机B收到广播包后，会将自己的MAC地址通过ARP协议响应包传给主机A，同时将A的IP地址和MAC地址的映射保存到自己的ARP缓存当中。主机A收到响应包后就可以与B进行通信，同时将B的IP地址和MAC地址的映射保存到自己的ARP缓存中。广播发送ARP请求，单播发送ARP响应。

RARP：MAC -> IP
RARP主要用于无盘工作站，因为无盘工作站配置的IP地址不能保存。工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系，当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络。



35、函数调用机制

从汇编角度来看：

<1>将实参按照从右到做的顺序压入栈中
<2>调用call转移指令跳转到被调函数的地址，call指令执行两个步骤，将下一条指令的地址push入栈，改变IP的值为被调函数的地址
<3>被调函数执行完后，将返回值保存到寄存器当中
<4>被调函数执行ret转移指令，将栈中下一条指令的地址pop给IP
<5>将之前push的实参pop出

为什么参数要从右到左压栈？

以printf为例，如果从左到右压栈，那么先压入format，之后再压入各个参数，之后下一个指令的ip入栈。此时要想知道参数的个数，就必须找到format，然而要找到format又需要知道format之后压入了几个参数，这样就陷入了死循环。如果从右到左压栈，那么栈顶指针加2即可找到format的位置，从而根据format中的"%"确定参数的个数。

如果函数不是不定参的，那么其实从左到右和从右到左压栈都是没关系的。



36、C++如何实现多态

C++多态的实现是由虚函数来完成的。
如果一个类中有虚函数，那么这个类会维护一个虚函数表，表中的每一项是指向一个虚函数的指针，所有的类对象共享一个虚函数表。当类对象被构造时，构造函数会为该对象设置一个指向虚函数表的指针。对于派生类来说，它也会维护一个自己的虚表，并在类对象被构造的时候设置虚表指针。这样当我们使用一个基类的指针或引用调用派生类对象的时候，就可以通过虚表指针找到对应的虚函数表进而找到真正的虚函数地址。
 ___________
|   vptr    |		base *ptr;
|___________|		derived *ptr2 = new derived;
| base data |		ptr = ptr2;
|   member  |		
|___________|		改变指针类型会改变指针的解析范围，内容不改变，因此
|  derived  |		vptr不会改变
|data member|
|___________|



37、虚拟继承

虚函数继承是为了解决多态的，虚拟继承是对对象内存布局的一种优化，是为了节约内存。解决方式如下：

A       A		A
 \     /	       / \		
  B   C	     -->      B   C
   \ /		       \ /
    D 		        D

可以说B、C虚拟继承于A，A为虚拟基类

虚拟继承的时候，子类会有一个指向父类的虚类指针，然后还要包含父类的所有内容。如果虚拟继承中子类父类都有各自的虚函数，在子类中就会有两个虚函数表指针，一个指向父类的虚表，一个指向子类的虚表，而普通的继承只有一个指向子类虚表的指针。有的编译器会将指向父类的虚类指针优化存储到虚表中负索引的位置。



38、TCP为什么能保证可靠传输，介绍一下滑动窗口和拥塞控制

TCP提供可靠的数据传输：

停止等待协议，没发送一个分组都要有一个确认消息与之对应，并且设置超时时间，当没有在规定时间收到确认消息就进行重传，保证数据不丢失。每个报文段都进行编号，保证数据按序到达且不重复。首部具有检验和，保证数据无差错。

TCP提供流量控制：

使用滑动窗口，接收方通过报文段首部的窗口字段告诉发送方允许发送的数据量，保证发送方的发送速率不至于过快而导致接收方无法及时处理。

滑动窗口：

在发送端和接收端各自维护着两个窗口，一个发送窗口和一个接收窗口。发送端和接收端可以根据TCP头部中的窗口字段告诉对方自己的接收窗口大小，保证发送方的发送速率不至于过快从而导致接收方无法及时处理。发送窗口其实就是发送缓冲中的一部分，发送窗口中的数据就是现在不需要等待确认就可以发送的数据，发送窗口之后的数据是已经发送且收到确认的数据，发送窗口之前是不允许发送的数据。与之对应，接收端的接收窗口其实就是接收缓存的一部分，接收窗口就是现在允许接收的数据，接收窗口之后的数据是已发送确认并且交付主机的数据，接收窗口之前的数据是不允许接收的数据。接收方在收到数据后会进行累积确认，告诉发送端下一个应该接收的数据序号，并将这些数据交付主机，然后将这些数据在接收缓存中删除，于是接收端的接收窗口就可以向前移动。发送端收到确认后就可以删除这些被确认的数据，根据确认报文段中的确认序号和窗口值向前滑动窗口，此时就可以继续发送新的报文段。对于迟迟收不到确认的报文段，在一段时间后会进行重传。

TCP提供拥塞控制：

TCP的发送方会维持一个拥塞窗口的状态变量，控制发送方发送窗口的大小。拥塞控制主要依靠四个算法来实现：慢开始、拥塞避免、快重传、快恢复。

<1>慢开始，初始时设置发送窗口大小为1个单位，随后每收到一个确认消息就将窗口的大小增加1，该增长是以指数的形式增长。TCP拥塞控制会提供一个慢开始门限，当窗口大小增长到大于慢开始门限时，就进行拥塞避免算法。

<2>拥塞避免，当窗口值大于慢开始门限，调整窗口的增长方式为每次只增加1，当数据传输过程中发生超时，就立即将慢开始门限减半，同时将发送窗口设置为1，继续执行慢开始过程。

<3>快重传，当接收方收到失序的报文段以后，就立即发出对缺失报文段的重复确认，，而不是等待自己发送数据时才捎带确认。发送方收到3个重复确认后就立即进行重传，而不用等到超时再重传。快重传一般和快恢复一起使用。

<4>快恢复，由于发送方此时可以接收到重复确认，所以此时网络很有可能并没有发生拥塞。所以此时会将慢开始门限减半，但并不执行慢开始算法，而是将发送窗口调整为慢开始门限调整后的大小，在进行拥塞避免算法。在采用快恢复算法时，慢开始算法只在TCP建立连接时和网络出现超时时再使用。



39、C++和Python有什么区别，各自的优势是什么

Python是一种脚本语言，是解释执行的，不需要经过编译，所以很方便快捷，能够很好的跨平台，写一些小工具小程序特别合适。但是Python代码是由解释器逐条解释执行或者说每次执行都要先翻译再运行，运行效率大大降低。

C++是一种需要编译后运行的语言，直接编译成机器可识别的二进制代码，因此，运行效率高，安全稳定。但是编译后的程序一般是不跨平台的。



40、内存只能容纳1亿，对10亿个数进行排序

使用归并排序。分为两个阶段:

<1>将10亿个数字等份成10份，对于每份数据采用适当的内部排序，并将结果保存到磁盘上。

<2>采用归并算法，归并第一阶段生成的归并段，直到只剩下一个归并段为止。

我们首先将1亿个空间分为3等份，一份作为输出缓存，两份作为输入缓存。将第1,2个归并段中三分之一的数据读取到输入缓存当中，对其进行归并操作。将结果保存到输出缓存，当输出缓存装满时便将数据保存到磁盘，继续进行归并。当输入缓存为空时，再从归并段中读取数据，直达第1,2个归并段的数据都排好序。对于剩下的归并段也进行两两归并，最终会得到5个较大的归并段。继续归并操作直到最终只剩下一个归并段。



41、TCP断开连接后客户端为什么要等待2MSL

MSL是报文最长生存时间，设置2个MSL的等待时间有两个原因：

<1>保证客户端发送的最后一个ACK报文段能够到达服务器。如果发生超时，可以在该时间段内进行重传，并重新设置2MSL时间。
<2>防止已经失效的报文段出现在下一次的连接中。



42、什么是cookie、session，两者的区别

cookie机制用于在客户端保持状态，session机制用于在服务器端保持状态。

cookie是由Web服务器保存在浏览器上的小文本文件，它可以包含有关用户的信息。无论何时用户链接到服务器，Web站点都可以访问cookie信息。cookie分为临时的和持续的，临时的cookie表示这个cookie的生命期是浏览器会话期间，关闭浏览器窗口，cookie就消失，这种cookie也称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里。持续的cookie会保存在硬盘上，关闭后再次打开浏览器仍然有效，当然有一个过期时间限制。

session是一种服务器端的机制，服务器使用一种类似于散列表的结构来保存信息。当程序要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含一个session标识（称为sessionID），如果已包含说明之前已经为该客户端创建过session，服务器按照sessionID将这个session检索出来使用。如果客户请求不包含sessionID，则为该客户端创建一个session并且生成一个与该session相关联的sessionID，并在本次响应中返回给客户端保存。保存这个sessionID的方式可以采用cookie。如果客户端禁止了cookie的使用，也可以使用其他机制保存。经常使用的技术是URL重写，就是将sessionID直接附加在URL路径的后面。

cookie和session的区别：

<1>cookie数据存放在客户的浏览器上，session数据存放在服务器上
<2>cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session
<3>session会在一定时间内保存在服务器上。当访问量增多，会影响服务器的性能。考虑到减轻服务器性能方面，应当使用cookie

所以建议：将登陆信息等需要保密的重要信息存放在session，其他信息保存在cookie



43、http特点

<1>支持客户/服务器模式
<2>简单快速：客户向服务器请求服务时，只需要传送请求方法和路径。请求方法常用的有get、head、post。
<3>灵活：http允许传输任意类型的数据对象
<4>无连接：每次连接只处理一个请求。服务器处理完用户的请求，并收到客户的应答后即断开连接。采用这种方式可以节省传输时间
<5>无状态：无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，它必须重传。



44、http和https的区别

<1>https需要到ca机构申请证书，一般免费证书较少，因而需要一定费用
<2>http是超文本传输协议，信息是明文传输；https则是具有安全性的ssl加密传输协议
<3>http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443
<4>http连接很简单，是无状态的；https协议是由ssl+http协议构建的可进行加密传输、身份认证的网络协议，比http协议安全

https安全加密机制：

https是基于http和ssl协议的安全传输协议，使用了非对称加密和对称加密。当浏览器和服务器建立TCP连接后，浏览器向服务器发送浏览器的ssl版本号和一些可选的加密算法，服务器选择一个支持的算法告诉浏览器；之后服务器将包含自己公钥的数字证书(该证书被CA进行了数字签名)发送给浏览器并且自己保存唯一的私钥，浏览器通过向CA查询该公钥是否可靠。之后浏览器使用服务器发来的公钥对将要使用的对称秘钥进行加密，然后发送给服务器，服务器用自己得私钥解密后得到对称秘钥。之后双方就可以使用该对称秘钥进行数据的加密和解密，保证数据传输的安全。


数字签名：

数字签名是用来确认发送方的身份，并且保证接收方收到的数据没有被篡改过。具体过程是：发送方使用自己的私钥对报文进行解密，该过程实际只是为了得到某种不可读的密文，不应该称之为解密。之后发送给接收方，接收方使用发送方的公钥进行加密，从而得到明文，因此可以确定是发送方发来的。因为私钥只有发送方有，所以中间人不可能进行伪造。当然，如果中间人获取发送方的公钥，就可以读取发送方的数据。如果要避免这种情况，可以在使用发送方的私钥解密后再用接收方的公钥进行加密，接收方收到数据后，先用自己的私钥进行解密，再用发送方的公钥进行加密。

如果只是为了鉴别报文是否是发送方发送的而不需要对报文进行加密，可以使用某种散列函数，对报文进行摘要，然后只对这部分摘要进行数字签名，并把签名后的摘要附加在报文之后。接收方收到后，使用发送方的私钥还原出摘要。之后使用相同的散列函数对报文进行摘要，看所得的摘要是否和发送方发送过来的摘要一样。这样就不需要对所有的报文进行数字签名，节约了成本。



45、C++从源代码到可执行程序经历了哪些过程

源代码 -> 预处理 -> 编译 -> 优化 -> 汇编 -> 链接 -> 可执行文件

<1>预处理：读取源程序，对其中的伪指令和特殊符号进行处理。伪指令包括宏定义指令、条件编译指令、头文件包含指令等。

<2>编译：检查是否所有的指令都符合语法规则，并将其翻译成等价的中间代码或者汇编代码。

<3>优化：优化一方面是对中间代码进行优化，包括将与循环无关的代码提到循环之外、删除无用的赋值等。另一方面，是与机器的硬件结构相关，考虑如何提高代码的性能、包括如何高效的利用寄存器来减少对内存的访问次数等。

<4>汇编：将汇编语言代码翻译成机器指令，形成若干个目标模块。

<5>链接：将编译汇编后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个完整的模块。



46、Linux查看日志

tail -n 10 test.log	第负10行以后
tail -n +10 test.log 	第10行以后
head -n 10 test.log	第10行以前
head -n -10 test.log	第负10行以前

过滤出关键词附近的日志

grep -C 10 '关键词' test.log	前后10行(包含本行)
grep -A 10 '关键词' test.log	后10行(包含本行)
grep -B 10 '关键词' test.log	前10行(包含本行)
或者
cat -n test.log | grep '关键词'		找到关键词行号，假设102
cat -n test.log | tail -n +92 | head -n 20	前后各10行

查找指定时间段的日志

sed -n '/2018-1-1 16:17:20/,/2018-1-1 16:17:36/p' test.log | more 分页查看



47、TCP,UDP报头格式

UDP首部开销小，8个字节4个字段，每个字段长度2字节。包括：
源端口、目的端口、报文长度、检验和。检验和检验报文首部和数据部分，IP协议只检验首部。

TCP首部开销大，最少20字节，最大60字节，包括：
源端口|目的端口
序号
确认号
数据偏移|保留位|控制位|窗口
检验和|紧急指针
检验和检验报文首部和数据部分，IP协议只检验首部。
数据偏移指出数据起始处距离报文段起始处有多远，实际上就是报头的长度。一共有4位，单位是4字节，因此，可以表达的最大的报头长度是60字节。



48、http状态码

http状态码有3个十进制数字组成，第一个十进制数字定义了状态码的类型。共5类型：
1**	消息，请求已被接受，需要继续处理
2**	成功，操作被成功接受并处理
3**	重定向，代表客户端需要采取进一步的操作才能完成请求
4**	客户端错误，请求包含语法错误或无法完成请求
5**	服务端错误，服务器在处理请求的过程中发生了错误

常见状态码：
200	请求成功
301	永久重定向
404	请求的资源不存在
500	内部服务器错误



49、http协议，一些报头字段的作用，如cache-control、keep-alive

Keep-Alive模式
http是无连接的协议，即每个请求/应答，客户端和服务器端都要新建一个连接，完成之后立即断开连接；当使用Keep-Alive模式时，可以使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，不需要重新建立连接。
启用Keep-Alive模式更高效，性能更高，因为避免了建立/释放连接的开销。

Keep-Alive模式，客户端如何判断请求所得到的响应数据已经接收完成？
<1>使用消息首部字段Conent-Length
Conent-Length表示实体内容长度，客户端或者服务器端可以根据这个值来判断数据是否接收完成。

<2>使用消息首部字段Transfer-Encoding
如果客户请求一个动态页面时，服务器是不可能预先知道内容大小，因此也就无法使用Conent-Length字段，这时就可以使用Transfer-Length字段中的chunk模式传输数据。
chunk编码将数据分成一块一块传输，以一个长度为0的块标识结束。每个块分为两部分，头部和正文，头部包含数据的大小。


Cache-Control
缓存控制，指定在请求/响应时是使用缓存中的数据还是重新从WEB上获取或者其他操作

请求：
no-cache（不要缓存的实体，要求现在从WEB服务器去取） 
max-age（只接受 Age 值小于 max-age 值，并且没有过期的对象） 
max-stale（可以接受过期的对象，但是过期时间必须小于 max-stale 值） 
min-fresh（必须保证接收的对象距离过期时间至少还有min-fresh） 
响应：
public(可以用 Cached 内容回应任何用户) 
private（只能用缓存内容回应先前请求该内容的那个用户） 
no-cache（可以缓存，但是只有在跟WEB服务器验证了其有效后，才能返回给客户端） 
max-age（只接受 Age 值小于 max-age 值，并且没有过期的对象） 
ALL: no-store（不允许缓存）



50、IP子网划分

IP地址根据网络ID的不同分为5种类型，A类地址、B类地址、C类地址、D类地址和E类地址。 

<1>A类IP地址：一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”，地址范围从1.0.0.1 到126.255.255.254。可用的A类网络有126个，每个网络能容纳1亿多个主机。 

<2>B类IP地址：一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.1到191.255.255.254。可用的B类网络有16382个，每个网络能容纳6万多个主机 。 

ps：127开头的IP主要用于测试，如127.0.0.1是回送地址。

<3>C类IP地址：一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”。范围从192.0.0.1到223.255.255.254。C类网络可达209万余个，每个网络能容纳254个主机。 

<4>D类地址用于多点广播：D类IP地址第一个字节以“lll0”开始，它是一个专门保留的地址。它并不指向特定的网络，目前这一类地址被用在多点广播（Multicast）中。多点广播地址用来一次寻址一组计算机，它标识共享同一协议的一组计算机。 

<5>E类IP地址：以“llll0”开始，为将来使用保留。 

在IP地址3种主要类型里，各保留了3个区域作为私有地址，其地址范围如下： 

A类地址中的保留地址：10.0.0.0～10.255.255.255 

B类地址中的保留地址：172.16.0.0～172.31.255.255

C类地址中的保留地址：192.168.0.0～192.168.255.255

另外IPv6地址长度为128位。



51、网络设备作用及所属层

<1>物理层

转发器(repeater)：有源转发器将信号解调后再生放大，再调制后传输。

集线器(hub)：实现星形拓扑的以太网，简单转发比特。 

网线、中继器、网关。

<2>数据链路层

适配器（网卡）：又称网络接口卡，用于计算机和局域网的通信。

网桥(bridge)：用于在数据链路层扩展以太网，根据MAC帧的目的地址对收到的帧进行转发和过滤。含有转发表。它隔离了冲突域，但不隔离广播域。

第二层交换机(layer2 switch)：多接口的网桥，又称以太网交换机或第二层交换机。可实现虚拟局域网VLAN(Virtual LAN)。 

<3>网络层

第三层交换机(layer3 switch)：能进行路由的交换机，具有一部分路由器功能。

路由器(router)：连接因特网中各局域网、广域网的设备。拥有路由选择处理机、交换结构、一组输入端口和一组输出端口。



52、主机字节序与网络字节序

主机字节序一般分为大端和小端两种，在X86平台上一般采用小端模式。

“小端”和“大端”表示多字节值的哪一端(小端或大端)存储在该值的起始地址。小端存在起始地址，即是小端字节序；大端存在起始地址，即是大端字节序。

<1>小端法(Little-Endian)就是低位字节排放在内存的低地址端即该值的起始地址，高位字节排放在内存的高地址端。 

<2>大端法(Big-Endian)就是高位字节排放在内存的低地址端即该值的起始地址，低位字节排放在内存的高地址端。

网络字节序是大端字节序，因此在进行网络编程的时候要注意将主机字节序统一转换为大端序。



53、TCP对应的协议和UDP对应的协议

TCP对应的协议：

<1>FTP：定义了文件传输协议，使用21端口。

<2>Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。

<3>SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。

<4>POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。

<5>HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。

UDP对应的协议：

<1>DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。

<2>SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。

<3>TFTP(Trival File Tran敏感词er Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。



54、说说C++ 和Java的区别

C++和java表面上看，java比较优秀的地方就是跨平台，也就是程序移植！而C++移植方面不如JAVA，而C++的优势，就是程序性能，运行速度，执行效率！C++一般用于开发系统程序，大型程序，驱动等对性能要求比较高的东西；而java的优势，一般在网页上，或者小型的软件上！java开发效率要比C++要高，但java的执行效率明显不如C++，因为它要靠java虚拟机运行java编写的程序。


55、栈空间在内存中有多大，可以怎么验证?

一般系统默认8M、4M、2M、1M，

验证：
<1>在函数或main()函数中定义局部变量，比如字符数组。局部变量一定要初始化。
<2>使用递归申请栈空间，每次申请1M，使用一个全局变量记录申请的次数

56、RBtree和Hashtable的区别?

<1> 红黑树是有序的，hashtable是无序的
<2>红黑树占用的内存较小，只保存相应的节点；hashtable需要预分配足够的内存存储散列表
<3>红黑树插入查找的时间复杂度是O(logN)；hashtable的时间复杂度是O(1)


57、server端(ipv4,TCP)的最大并发连接数

server最大tcp连接数：server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此server端tcp连接4元组中只有remoteip（也就是client ip）和remoteport（客户端port）是可变的，因此最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方。



58、网络中出现拥塞的原因是什么?

<1>结点缓存区容量有限，当多个数据到达结点需要被处理时，需要排队等候，当数据过多超过了缓存区的容量，就会造成分组的丢失。不断的丢失不断的重传就会造成网络拥塞。

<2>带宽容量的限制，低速的链路难以应付高速的数据流传输

<3>处理器性能限制，路由器CPU处理效率过低，不能满足高速链路的需求。



59、数据链路层的下层是MAC，上层是什么?有什么作用?

上层是LLC层，主要功能包括：
<1>向上层提供服务
<2>数据包的分段和重组
<3>保证数据包的顺序传输
<4>对传输可靠性进行保障和控制

MAC层主要功能：
<1>对数据帧的封装和卸载
<2>对帧的寻址和识别
<3>帧的接收和发送
<4>帧的差错控制



60、IP为什么要进行分片处理

IP层接收到一份要发送的IP数据报时，它要判断向本地的那个接口发送数据，并且查找该接口的MTU，也就是链路层所能发送的帧中数据部分的最大长度。如果数据报的长度大于该长度，就需要进行分片。分片可以发生在发送端主机上，也可以发送在中间路由器上。



61、



62、操作系统产生死锁的4个条件

<1> 资源是互斥的。在一段时间内，某个资源只能被一个进程访问。

<2> 请求和保持条件。一个进程占有一些资源又去申请另外的资源而又得不到满足，从而该进程被阻塞，但不释放它占有的资源。

<3> 不可抢占条件。进程已获得的资源只能自己释放不能被其他进程抢占。

<4> 循环等待条件。各个进程互相等待其他进程占有的资源，形成循环等待。


处理死锁的方法：

<1> 预防死锁，破坏四个必要条件中的1个或多个，其中互斥不可破坏。

破坏请求和保持条件：所有的程序在运行前，必须一次性申请在整个运行过程中需要的全部资源。只要有一种资源得不到满足就让该进程等待。

破坏不可抢占条件：如果一个进程占有一些资源又去申请其他的资源但又得不到满足，它就必须释放已经占有的资源。

破坏循环等待条件：对系统所有的资源进行排序，进程只能按照序号递增的顺序请求资源，同类资源要一起请求。

<2> 死锁避免

在每次资源动态分配的过程中，都要检测系统是否会进入不安全状态，如果会，就不分配资源。典型的避免死锁的算法就是银行家算法，银行家算法就是根据各个进程总共需要的资源量和已经占有的资源量以及系统中未分配的资源量对资源分配进行控制，当有进程申请资源的时候，计算在本次分配资源后，是否有一个序列能使所有的进程顺利进行，如果没有，就不予以分配。

<3> 死锁检测与解除

解除死锁的方法：抢占资源、终止或撤销进程



63、socket编程的函数有哪些?是一个什么调用关系?

服务器端：socket -> bind -> listen -> accept -> read/write -> close

客户端：socket -> connect -> write/read -> close

IO复用：select、epoll

多进程：fork、wait & waitpid（等待子进程终止，销毁僵尸进程）、signal（信号处理）

多进程：pthread_create、pthread_join（等待线程终止）



64、Myslq会不会? 底层是怎么做的?



65、

66、内存的页面置换算法

最佳置换算法(OPT):
理想情况下的算法，将之后长时间不使用的页面换出。

先进先出算法(FIFO)

最近最久未使用算法(LRU):
将过去最长一段时间内不曾使用的页面换出

Clock置换算法(LRU的近似实现)



67、内核态和用户态的区别?

当进程处于内核态时，执行的就是内核代码，此时处理器具有最高的特权级，并且使用的栈是内核栈。当进程处于用户态时，执行的就是用户自己的代码，此时处理器具有最低的特权级，使用的栈是用户栈。

在Linux进程中，有4GB的地址空间，其中3-4G部分是大家共享的，是内核态的地址空间。用户执行一个程序，开始是运行在用户态，如果要使用系统调用或者产生了系统中断或者发生了异常（缺页异常等），此时就会切换到内核态，即进入3-4G的内核地址空间中去执行。完成后再切回到用户态。用户态不能访问内核态的数据和代码。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。

具体的切换过程：
<1> 从当前进程描述符中提取出指向内核栈的指针，切换到内核栈
<2> 将当前的工作现场保存到内核栈中，同时还保存了当前程序的下一条指令
<3> 将要执行的内核态代码的cs：ip装入相应的寄存器，开始执行内核程序


68、Linux的开机自启动过程

（1）读取ROM芯片，加载BIOS(基本输入输出系统)。该过程包括硬件检查以及设置设备启动顺序

（2）读取主引导记录。BIOS按照启动顺序，读取相应设备上的第一个扇区，也就是读取最前面的512个字节。如果512个字节的最后两个字节是0x55和0xAA，表明这个设备可以启动，否则将控制权交给启动顺序的下一个设备。最前面的这512个字节就叫做“主引导记录”（Master_Boot_Record，缩写为MBR）。

“主引导记录”的作用是告诉计算机，到硬盘的哪一个位置去找操作系统，其中还包括了分区表。

（3）计算机在读取MBR后，运行实事先安装的“启动管理器”，也就是Boot_Loader，由用户选择启动哪一个操作系统。Linux中最流行的启动管理器是Grub。

（4）计算机将控制权交给操作系统后，首先读入/boot目录下的内核文件。内核加载成功后启动init进程，初始化系统环境。许多程序需要开机启动，也就是Linux中的守护进程，init进程负责启动这些进程。

（5）开机启动程序加载完成后，就进入用户登陆界面，用户输入用户名和密码。此时全部启动过程完成。


69、内联函数和宏指令有什么区别?

宏：是用#define定义，是预处理对宏的替换，不检查函数参数，返回值，只能简单的替换，有安全隐患；

内联函数：在函数前加上inline，通过编译器控制来实现，取消了函数的参数压栈，减少了调用的开销，内联函数的执行速度比一般的函数要快；

在C++中，类的内部定义的函数体，被编译器优化，看作是内联函数；

但是内联函数块不能太大，过大的话，编译器会放弃内联的方式，采用普通方式调用函数；内联函数是安全的；



70、为什么在公有继承链中基类的析构函数要被声明成虚函数，一个不被继承的类析构函数被声明成虚函数好不好？

(1) 因为：delete 对象时，(一般多态都是父类的指针)调用的是基类的析构函数，只能销毁基类对象，而无法销毁派生类对象，有可能发生内存泄漏！！！

(2) 当基类的析构函数声明为虚函数，那么派生类的析构函数也是虚函数，此时调用delete p时发生动态绑定，运行时会根据实际类型调用该对象的虚函数。

(3) 当然，并不是要把所有类的析构函数都写成虚函数。只有当一个类是基类(即希望被继承)的时候才需要声明成虚函数，因为虚函数的作用是实现多态，而多态是建立在继承的基础上。单一类不能把析构函数写成虚函数，因为会产生额外的开销，比如虚表的创建和虚指针的定义。



71、fork之后父进程和子进程的栈变量是私有还是公有，堆变量呢，全局变量呢，常量呢，static 变量呢？

都是私有的



72、服务端一直阻塞着(调用sleep)，客户端调用send会返回错误吗？

发送数据时，数据首先从应用程序缓冲区复制到发送端套接字发送缓冲区中，这个过程使用类似write函数完成的。write成功仅表示数据成功复制到套接字发送缓冲区，而不是已经成功到达对端。之后内核协议将套接字发送缓冲区中的数据发送到对端主机的套接字接收缓冲区，这个过程不受应用程序的控制。因此，服务端即使是在阻塞着，数据也还是可以到达服务端套接字的接收缓冲区当中，但是却不能将接收缓冲区中的数据复制到应用程序缓冲区，因此，当发送的数据越来越多，以至于发送端的发送缓冲区和接收端的接收缓存区都被填满，此时send就被阻塞了直到有空间为止，不会返回错误。



73、服务端在调用listen之后调用sleep，客户端connect之后会返回错误吗？

因为是TCP连接，客户端在进行connect()时会发生三次握手

调用connect()时内核发送一个SYN同步，若无响应则等待6s后再次发送一个，仍无响应则等待24s再发送一个，若总共等了75s后仍(有超时重传的机制)未收到响应则返回 ETIMEDOUT 错误



74、recv返回值为0，是什么意思？

<0 出错 =0 连接关闭 >0 接收到数据大小



75、C++对象模型

在C++对象模型中，非静态数据成员被配置于每一个类对象之内，静态数据成员则被存放在类对象之外，静态区（全局区）。静态和非静态成员函数也存放在类对象之外，代码区。对于虚函数，每个类会产生一堆指向虚函数的指针，放在一个表格中，这个表格就是虚函数表。每一个类对象都会安插一个指针指向相关的虚函数表，虚函数表存放在静态区。对于类继承，基类对象的数据成员会被直接放置于继承类对象中。如果是虚拟继承，则会在类对象中安插指向每一个虚基类的指针，有的编译器会使用一个虚基类表保存所有的指针；有的编译器直接在虚函数表上进行扩展，负索引位置上的指针就是指向虚基类的指针。



76、什么是父子进程、僵尸进程、孤儿进程、守护进程

父子进程：
一个进程调用fork或者exec函数产生一个新的进程，此时就称第一个进程是第二个进程的父进程，第二个进程是第一个进程的子进程。

僵尸进程：
一个进程使用fork或者exec创建子进程，如果子进程退出，而父进程没有调用wait或者waitpid获取子进程的状态信息，那么子进程的进程描述符就仍然保留在系统中，这种进程称为僵尸进程。

孤儿进程：
一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程会被init进程收养，并由init进程进行处理。

守护进程：
守护进程就是在后台运行，不与任何终端关联的进程，它周期性的执行某种任务或者等待处理某些发生的事件，例如web服务，守护进程通常是开机自启动。



77、master公式

T(n) = aT(n/b) + T(n^d)

其中：a为生成的子问题数，b表示每次递归的规模是原来的1/b，T(n^d)是分解和合并的时间复杂度

(1)若d < logb a，时间复杂度为O(n^(logb a));
(2)若d = logb a，时间复杂度为O((n^d)*logn);
(3)若d > logb a，时间复杂度为O(n^d);



78、硬链接和软链接区别

软链接：
软链接相当于windows中的快捷方式，它会使用一个新的inode，软链接的inode中存放的是指向文件的路径。删除软链接不影响被指向的文件，但如果被指向的源文件被删除，则相关的软链接就变成了死链接。

硬链接：
硬链接使用和源文件相同的inode，此时原来文件的inode链接数加一。删除一个硬链接不会影响其他的文件，只有所有的硬链接文件都删除了，这个文件才被真正的删除。

区别：
硬链接记录的是目标的inode，软链接记录的是目标的path。
软链接可以跨文件系统进行链接，也就是可以跨分区；硬链接不能跨文件系统，即不能跨分区。
软链接可以对文件或目录进行创建，硬链接不能对目录进行创建，只能对文件创建。



79、重写与重载的区别

重写一般用在父类和子类之间，子类重写父类的方法，要求与父类具有相同的方法名和参数列表以及返回值。

重载是在一个类中，具有相同的方法名，但是参数列表必须不同，包括个数、类型或者顺序。方法的返回值可以相同也可以不相同，不能以返回值来区分各个方法。

80、extend C的作用



81、数组指针和指针数组

数组指针：
int (*p)[n]
()优先级高，说明p是一个指针，指向一个整型的一维数组。p+1时，p要跨过n个整型数据的长度。

指针数组：
int *p[n]
[]优先级高，先与p结合成为一个数组，再由int*说明这个数组的数据类型是int型指针。



82、二叉树结点数、度、边之间的关系

n = n0 + n1 + n2
e = n - 1
e = n1 + 2n2 
n2 = n0 - 1
(n0 -> 叶子结点，n1 -> 度为1的结点，n2 -> 度为2的结点)



83、数组和指针的区别

数组是用来存放多个元素的，它会在内存上分配一个连续的空间，记录分配的空间的大小，并且指向第一个元素的位置。读取元素的时候是根据偏移量计算出位置直接读取的，不像指针一样需要访问两次内存地址。调用sizeof()的结果是所有元素总共的大小。

指针是一个变量，只不过它的值是一个地址，这个地址指向了真正的数据。因此，在读取其中的数据的时候，需要两次访问内存地址。定义指针的类型并不是定义它的值的类型，而是它的值的值的类型。所以，对任意的指针调用sizeof()的结果都是4（32位系统）。数组作为函数的参数的时候，会自动转换为指向第一个元素的指针。



84、内存泄漏怎么办

<1>检查显式的new与delete、malloc和free是否匹配
<2>考虑隐式的内存泄漏，比如在实现多态的过程中，是否只析构了父类而没有析构子类，这种情况下最好将父类定义成虚函数。再如，delete掉一个void*类型的指针，导致没有调用对象的析构函数。又如，创建了一个动态数组，delete的时候没有加[]使得只析构了数组的第一个对象。
<3>最有效的方式是使用智能指针，可以自动释放不再使用的空间，智能指针的类型有shared_ptr、unique_ptr、weak_ptr。



85、hello world程序执行过程发生了什么

首先源代码经过预处理、编译、优化、汇编、链接形成可执行文件，在运行程序的时候，操作系统找到程序的相关信息，检查其类型是否是可执行文件，并根据程序首部信息确定代码和数据存放的位置。操作系统创建一个进程并将可执行文件映射到该进程结构，同时设置cpu的上下文环境，跳到程序的开始处。之后执行程序的第一条指令，发生缺页异常，系统会分配一页物理内存将所需要的页面置换到内存中继续执行。程序执行系统调用将hello_world写到显示器上。显示器设备是由一个进程控制的，因此在将hello_world写到显示器的过程中，操作系统先将要写的字符串送给管理显器示设备的进程，显示器设备将这些字符转化成一组控制数据信号并激发液晶屏幕，最终就将hello_world显示出来了。



86、模板类的声明和定义为什么需要写一起

当我们创建一个模板类特例的时候，也就是实例化的时候，编译器会在相关的头文件中找到模板的声明，但是没有模板的定义，这时候就不能进行实例化。但这时并不报错，因为编译器认为模板定义在其他的文件中。之后编译器找到模板类的定义，但此时它并不能进行实例化，因为它根本不知道模板的类型参数。所以就会报出无定义成员的错误。



87、epoll的水平触发和边缘触发

水平触发：只要有可读或可写，事件会一直触发。
边缘触发：只有从不可读变为刻度、从不可写变成可写，事件才会触发。

边缘触发需要将accept接受的套接字设置成非阻塞的，因为边缘触发，事件一旦触发了，就需要用户一直读，如果设置成阻塞的，当缓冲区没有数据可读的时候，它再去读就会造成阻塞。使用非阻塞方式的话，当缓冲区无数据的时候就会返回一个错误来告诉用户缓冲区为空。
